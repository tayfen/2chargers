{"cells":[{"cell_type":"markdown","metadata":{},"source":["### how to\n","- gather geo segments < 200 stations\n","- scan all segments\n","- maybe need some reformat of data to fit your requirements "]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"290c756db6144fd281025087ebb629a7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":58,"execution_start":1668941173423,"source_hash":"3551cf23","tags":[]},"outputs":[],"source":["import pandas as pd\n","import requests\n","import joblib\n","import ast"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["с нуля заполняю сегменты\n","# есть какая-то проблема с переходом от -180 + 180, поэтому делим сразу на сегмента без этого перехода\n","initial_segments = [[[38.71443081148476, 27.055894707637356], [78.83427199842515, 180]], [[38.71443081148476, -180], [78.83427199842515, -168.4183446606007]]]\n","new_segments = []\n","\n","def divide_segment(segment):\n","    lat1, lon1, lat2, lon2 = segment[0][0], segment[0][1], segment[1][0], segment[1][1]\n","    return [[[lat1, lon1], [lat2, lon1 + (lon2-lon1)/2]], [[lat1, lon1 + (lon2-lon1)/2], [lat2, lon2]]]\n","\n","def get_loc(segment):\n","    global new_segments\n","    print(f'cur seg - {segment}')\n","    json = {\"userCoordinates\":segment,\n","    \"connectorIds\":[],\n","    }\n","    r = requests.post('https://2chargers.net/api/addresses', json=json)\n","    if r.status_code != 200:\n","        print(r)\n","        print(f'error - {r.status_code} on seg {segment}')\n","        #break\n","    else:\n","        response_dict = r.json()\n","        if len(response_dict) == 200:\n","            print(f'seg division - {segment}')\n","            seg1, seg2 = divide_segment(segment)\n","            print(f'new segs - {seg1}, {seg2}')\n","            get_loc(seg1)\n","            get_loc(seg2)            \n","        else:\n","            print(f'seg append, number of stations - {len(response_dict)} - {segment}')\n","            new_segments.append(segment)\n","            return None\n","\n","        #companies_df = pd.DataFrame.from_dict(response_dict['companies'])\n","        #companies_df.to_csv('companies.csv', encoding='utf-8', index=False)\n","\n","for seg in initial_segments:\n","    get_loc(seg)"]},{"cell_type":"code","execution_count":156,"metadata":{"cell_id":"04a7165c41bf4162b962b86370cea509","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":14,"execution_start":1669116620088,"source_hash":"345973bf","tags":[]},"outputs":[],"source":["class TwoChargers():\n","    def __init__(self, base_url = 'https://2chargers.net/api/'):\n","        self.base_url = base_url\n","        self.post_methods = ['filters', 'cars', 'companies', 'addresses']\n","        self.get_methods = ['stations', 'traffic', 'loc_info']\n","    \n","    def request(self, method, json = None, loc_id = None, week_day = None):\n","        orig_method = method\n","        if method in self.post_methods:\n","            request = requests.post\n","        elif method in self.get_methods:\n","            request = requests.get\n","            if method == 'loc_info':\n","                method = f'addresses/{loc_id}'\n","            elif method == 'traffic':\n","                method = f'addresses/{loc_id}/{method}/{week_day}'\n","            elif method == 'stations':\n","                method = f'addresses/{loc_id}/{method}'\n","            else:\n","                print('unknown get method')\n","                return None    \n","        else:\n","            print('unknown method')\n","            return None\n","        r = request(f'{self.base_url}{method}', json=json)\n","        if r.status_code != 200:\n","            print(f'{r.status_code} for {self.base_url}{method}')\n","            return None\n","        else:            \n","            response_dict = r.json()\n","            method = orig_method\n","            return self.proc(method, response_dict)            \n","    \n","    def proc(self, method, response_dict):\n","        if method == 'filters':\n","            connectors = response_dict['connectors']\n","            for connector in connectors:\n","                connector['decription'] = connector['extra']['explanation']\n","                del connector['extra']\n","            connectors_df = pd.DataFrame.from_dict(connectors)\n","            connectors_df.to_csv('connectors.csv', encoding='utf-8', index=False)\n","            return connectors_df\n","            \n","        elif method == 'companies':\n","            companies_df = pd.DataFrame.from_dict(response_dict)\n","            companies_df.to_csv('companies.csv', encoding='utf-8', index=False)\n","            return companies_df\n","        \n","        elif method == 'cars':\n","            cars_df = pd.DataFrame.from_dict(response_dict)\n","            cars_df.to_csv('cars.csv', encoding='utf-8', index=False)\n","            return cars_df\n","\n","        elif method == 'addresses':\n","            if len(response_dict) == 200:\n","                print('decrease area, not all stations scraped')\n","            return pd.DataFrame.from_dict(response_dict)\n","        \n","        elif method == 'traffic':\n","            return response_dict\n","\n","        elif method in self.get_methods:\n","            return pd.DataFrame.from_dict(response_dict)                        \n","            \n","    def scan_all_segments(self):\n","        segments = joblib.load('segments')\n","\n","        def divide_segment(segment):\n","            lat1, lon1, lat2, lon2 = segment[0][0], segment[0][1], segment[1][0], segment[1][1]\n","            return [[[lat1, lon1], [lat2, lon1 + (lon2-lon1)/2]], [[lat1, lon1 + (lon2-lon1)/2], [lat2, lon2]]]\n","\n","        stations = []\n","        segments_to_remove = []\n","        new_segments = []\n","        for segment in segments:\n","            json = {\"userCoordinates\":segment,\n","                \"connectorIds\":[],\n","                }\n","            segment_stations = self.request('addresses', json)\n","            if len(segment_stations) == 200:\n","                print('need seg division')\n","                segments_to_remove.append(segment)\n","                seg1, seg2 = divide_segment(segment)\n","                new_segments.extend([seg1, seg2])                \n","            else:\n","                stations.append(segment_stations)\n","        \n","        for segment in new_segments:\n","            json = {\"userCoordinates\":segment,\n","                \"connectorIds\":[],\n","                }\n","            segment_stations = self.request('addresses', json)\n","            if len(segment_stations) == 200:\n","                print('ALARM, need new seg division')\n","                segments_to_remove.append(segment)\n","                seg1, seg2 = divide_segment(segment)\n","                new_segments.extend([seg1, seg2])                \n","            else:\n","                stations.append(segment_stations)\n","        \n","        # надо обновить список сегментов\n","        if new_segments:\n","            for segment in segments:\n","                if segment not in segments_to_remove:\n","                    new_segments.append(segment)\n","\n","            joblib.dump(new_segments, 'segments')\n","        \n","        all_stations = pd.concat(stations)\n","        all_stations.loc[all_stations.country_id == 1].to_csv('ru_station_locations.csv', encoding='utf-8', index=False)\n","        return all_stations\n","\n","    def scan_all_locations(self):\n","        stations = []\n","        ru_station_locations = pd.read_csv('ru_station_locations.csv')\n","        for idx, row in ru_station_locations.iterrows():\n","            loc_id = row.id\n","            st_info = self.request('stations', loc_id = loc_id)\n","            st_info['location_id'] = loc_id\n","            stations.append(st_info)\n","        all_stations = pd.concat(stations)\n","        all_stations.to_csv('all_stations.csv', encoding='utf-8', index=False)\n","        return all_stations\n","\n","    def get_traffic(self):\n","        stations = []\n","        ru_station_locations = pd.read_csv('ru_station_locations.csv')\n","        for idx, row in ru_station_locations.iterrows():\n","            loc_id = row.id\n","            station_load = {}\n","            for day in range(1,8):\n","                station_load[day] = {}\n","                st_traffic = self.request('traffic', loc_id = loc_id, week_day=day)\n","                if not st_traffic:\n","                    break\n","                for h in st_traffic:\n","                    if h['count'] != 0:\n","                        station_load[day][h['hour']] = h['count']\n","            stations.append({'location_id' : loc_id, 'traffic' : str(station_load)})\n","        all_stations_traffic = pd.DataFrame.from_dict(stations)\n","        all_stations_traffic.to_csv('all_stations_traffic.csv', encoding='utf-8', index=False)\n","        return all_stations_traffic\n","\n","    def format_output(self):        \n","        ru_station_locations = pd.read_csv('ru_station_locations.csv')\n","        ru_station_locations.fillna('', inplace=True)\n","        stations_data = pd.read_csv('all_stations.csv')\n","        stations_data.fillna('', inplace=True)\n","\n","        stations = []\n","\n","        connectors = {'type_2' : [7, 50],\n","                    'type_1' : [4],\n","                    'gbt' : [12, 13],\n","                    'ccs' : [2,37,38],\n","                    'chademo' : [3]}\n","\n","        for _, location in ru_station_locations.iterrows():\n","            station = stations_data.loc[stations_data.location_id == location.id]\n","\n","            powers = {}\n","            price = {}\n","            for key in connectors.keys():\n","                powers[key] = station.loc[station.connector_id.isin(connectors[key])].kwt.tolist()\n","\n","                price[key] = station.loc[station.connector_id.isin(connectors[key])].price_per_kwt.tolist()\n","                if '' in powers[key]:\n","                    powers[key].remove('')\n","\n","                if '' in price[key]:\n","                    price[key].remove('')\n","                \n","            for key in list(price.keys()):\n","                if len(price[key]) == 0:\n","                    del price[key]\n","                else:\n","                    price[key] = sum(price[key]) / len(price[key])\n","\n","            if location.serving_company:\n","                company = ast.literal_eval(location.serving_company)['name']\n","            else:\n","                company = ''\n","\n","            if location.working_all_time:\n","                working_time = '0-24'\n","            else:\n","                working_time = location.working_hours\n","            \n","            st_info = {'loc_id' : location.id,\n","            'name' : location['name'],\n","            'addr' : location.address,\n","            'coords' : f'{location.latitude}, {location.longitude}',\n","            'manufacturer' : '',\n","            'company' : company,\n","            'price' : price,\n","            'working_time' : working_time,\n","            'phone' : location.phone,\n","            'desc' : location.description,\n","            'type' : location.icon_type,\n","            'country' : location.country_id,\n","            'area' : location.area_id,\n","            'city' : location.city_id,\n","            'type_2_num' : len(powers['type_2']),\n","            'type_2_power' : sum(powers['type_2']),\n","            'ccs_num' : len(powers['ccs']),\n","            'ccs_power' : sum(powers['ccs']),\n","            'chademo_num' : len(powers['chademo']),\n","            'chademo_power' : sum(powers['chademo']),\n","            'gbt_num' : len(powers['gbt']),\n","            'gbt_power' : sum(powers['gbt']),\n","            'type_1_num' : len(powers['type_1']),\n","            'type_1_power' : sum(powers['type_1']),\n","            }\n","            \n","            stations.append(st_info)\n","        \n","        cols = ['loc_id', 'name', 'addr', 'coords', 'manufacturer', 'type_2_num', 'type_2_power', \n","        'ccs_num', 'ccs_power', 'chademo_num', 'chademo_power', 'gbt_num', 'gbt_power', 'type_1_num', 'type_1_power',\n","        'company', 'price', 'working_time', 'phone', 'desc', 'type', 'country', 'area', 'city']\n","\n","        needed_format = pd.DataFrame(columns=cols)\n","        needed_format = pd.concat([needed_format, pd.DataFrame.from_dict(stations)])\n","        needed_format.to_csv('stations_formatted.csv', encoding='utf-8', index=False)\n","        return needed_format\n"]},{"cell_type":"markdown","metadata":{},"source":["у twochargers разные методы есть, кажется, траффик так и не был интересен, просто сканирование + форматирование"]},{"cell_type":"markdown","metadata":{},"source":["pipeline\n","\n","1 - prep segments\n","\n","2 - scan locations for segments\n","\n","3 - scan stations on locations\n","\n","4 - prep formatted output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["two_chargers_parser = TwoChargers()\n","df = two_chargers_parser.scan_all_segments()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["two_chargers_parser = TwoChargers()\n","df = two_chargers_parser.scan_all_locations()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2024d09dfda744eb8025000c2997b4d2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1877837,"execution_start":1668947106211,"is_output_hidden":true,"source_hash":"42d568b0","tags":[]},"outputs":[],"source":["two_chargers_parser = TwoChargers()\n","df = two_chargers_parser.format_output()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":104,"metadata":{"cell_id":"4cb24a3f40b64212897dedfca08eb4c2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1668861304732,"source_hash":"8620a6ea","tags":[]},"outputs":[],"source":["# формат гео - lat, lon - lat, lon, например - [[55.765158, 49.18338],[55.965158, 49.58338]]\n","#'latitude': 55.765158,\n","#'longitude': 49.18338\n","\n","#оригинальный запрос\n","json = {\"userCoordinates\":[[55.765158, 49.18338],[55.965158, 49.58338]],\n","\"connectorIds\":[],\n","\"availableIds\":[0,1,2,3],\n","\"companyIds\":[45,44,42,41,40,39,38,37,36,35,34,32,31,30,29,28,27,26,25,24,23,22,21,\n","                19,18,17,16,13,12,11,10,8,7,6,5,4,3,2,1],\n","\"connectors\":[{\"id\":2,\"type_id\":0},{\"id\":37,\"type_id\":0},{\"id\":38,\"type_id\":0},\n","                {\"id\":3,\"type_id\":0},{\"id\":39,\"type_id\":0},{\"id\":41,\"type_id\":0},\n","                {\"id\":40,\"type_id\":0},{\"id\":1,\"type_id\":0},{\"id\":50,\"type_id\":0},\n","                {\"id\":7,\"type_id\":0},{\"id\":4,\"type_id\":0},{\"id\":17,\"type_id\":0},\n","                {\"id\":42,\"type_id\":0},{\"id\":5,\"type_id\":0},{\"id\":13,\"type_id\":0},\n","                {\"id\":12,\"type_id\":0},{\"id\":9,\"type_id\":0},{\"id\":23,\"type_id\":0},\n","                {\"id\":24,\"type_id\":0},{\"id\":25,\"type_id\":0},{\"id\":26,\"type_id\":0},\n","                {\"id\":14,\"type_id\":0},{\"id\":11,\"type_id\":0},{\"id\":10,\"type_id\":0},\n","                {\"id\":49,\"type_id\":0},{\"id\":30,\"type_id\":0},{\"id\":44,\"type_id\":0},\n","                {\"id\":8,\"type_id\":0},{\"id\":19,\"type_id\":0},{\"id\":29,\"type_id\":0},\n","                {\"id\":6,\"type_id\":0},{\"id\":33,\"type_id\":0},{\"id\":34,\"type_id\":0},\n","                {\"id\":31,\"type_id\":0},{\"id\":32,\"type_id\":0},{\"id\":35,\"type_id\":0},\n","                {\"id\":15,\"type_id\":0},{\"id\":43,\"type_id\":0},{\"id\":16,\"type_id\":0},\n","                {\"id\":18,\"type_id\":0},{\"id\":36,\"type_id\":0},{\"id\":28,\"type_id\":0},\n","                {\"id\":27,\"type_id\":0}],\n","\"stationTypeIds\":[],\n","\"zoomLevel\":9.0,\n","\"onlyFast\":False,\n","\"car_id\":None,\n","\"kilowattRange\":{\"min\":0.0,\"max\":0.0},\n","\"showStationsWithoutKwt\":False,\n","\"withoutCompany\":False,\n","\"hideDeleted\":False}\n","\n","# минимальный\n","json = {\"userCoordinates\":[[55.765158, 49.18338],[55.965158, 49.58338]],\n","\"connectorIds\":[],\n","}"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8a0668b3-9bed-4dec-8f71-91785d133502' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"253f7e4855e84701b7986b6962ebcefc","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
